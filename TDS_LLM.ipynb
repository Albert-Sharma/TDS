{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuQnZnDrHgFYa21OMy4mm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Albert-Sharma/TDS/blob/main/TDS_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "saqV8WeP5byz"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('AIR_PROXY_TOKEN')"
      ],
      "metadata": {
        "id": "huEmx8zN90-c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(\"https://aiproxy.sanand.workers.dev/openai/v1/models\", headers={\n",
        "    \"Authorization\": f\"Bearer {api_key}\"\n",
        "    })"
      ],
      "metadata": {
        "id": "nPNibbx098OX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5Mbpq1OxDzpY",
        "outputId": "4cb98ffe-106a-47f5-d646-f9067d8e7cff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'object': 'list',\n",
              " 'data': [{'id': 'dall-e-3',\n",
              "   'object': 'model',\n",
              "   'created': 1698785189,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'whisper-1',\n",
              "   'object': 'model',\n",
              "   'created': 1677532384,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'tts-1',\n",
              "   'object': 'model',\n",
              "   'created': 1681940951,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'dall-e-2',\n",
              "   'object': 'model',\n",
              "   'created': 1698798177,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'tts-1-hd-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1699053533,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4o',\n",
              "   'object': 'model',\n",
              "   'created': 1715367049,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'tts-1-hd',\n",
              "   'object': 'model',\n",
              "   'created': 1699046015,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4-turbo-2024-04-09',\n",
              "   'object': 'model',\n",
              "   'created': 1712601677,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4-turbo',\n",
              "   'object': 'model',\n",
              "   'created': 1712361441,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1698959748,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4-0613',\n",
              "   'object': 'model',\n",
              "   'created': 1686588896,\n",
              "   'owned_by': 'openai'},\n",
              "  {'id': 'gpt-4-1106-preview',\n",
              "   'object': 'model',\n",
              "   'created': 1698957206,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4o-2024-05-13',\n",
              "   'object': 'model',\n",
              "   'created': 1715368132,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4-0125-preview',\n",
              "   'object': 'model',\n",
              "   'created': 1706037612,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4',\n",
              "   'object': 'model',\n",
              "   'created': 1687882411,\n",
              "   'owned_by': 'openai'},\n",
              "  {'id': 'text-embedding-3-small',\n",
              "   'object': 'model',\n",
              "   'created': 1705948997,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-4-turbo-preview',\n",
              "   'object': 'model',\n",
              "   'created': 1706037777,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'text-embedding-3-large',\n",
              "   'object': 'model',\n",
              "   'created': 1705953180,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-16k',\n",
              "   'object': 'model',\n",
              "   'created': 1683758102,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'babbage-002',\n",
              "   'object': 'model',\n",
              "   'created': 1692634615,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-0125',\n",
              "   'object': 'model',\n",
              "   'created': 1706048358,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'tts-1-1106',\n",
              "   'object': 'model',\n",
              "   'created': 1699053241,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo',\n",
              "   'object': 'model',\n",
              "   'created': 1677610602,\n",
              "   'owned_by': 'openai'},\n",
              "  {'id': 'gpt-3.5-turbo-instruct',\n",
              "   'object': 'model',\n",
              "   'created': 1692901427,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'gpt-3.5-turbo-instruct-0914',\n",
              "   'object': 'model',\n",
              "   'created': 1694122472,\n",
              "   'owned_by': 'system'},\n",
              "  {'id': 'text-embedding-ada-002',\n",
              "   'object': 'model',\n",
              "   'created': 1671217299,\n",
              "   'owned_by': 'openai-internal'},\n",
              "  {'id': 'davinci-002',\n",
              "   'object': 'model',\n",
              "   'created': 1692634301,\n",
              "   'owned_by': 'system'}],\n",
              " 'monthlyCost': 0.0012389999999999999,\n",
              " 'cost': 0,\n",
              " 'monthlyRequests': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"Gru and his family, including the adorable but misfiring loyal minions, move to a safe house in a new neighbourhood, feigning new identities and battling new sets of challenges. The bunch must fight the hostility of their snooty neighbours and befriend the person who can blow their cover. If this isn't enough, they must also fight Maxime and revisit Gru's old school to steal a honey badger. Little Agnes and her big eyes ensure the cuteness factor is intact in the franchise and giving her company is Gru's tiny toddler, new addition to the family. An unconventional looking man with a tough exterior and soft heart has always been the USP of the Despicable franchise. It has always had a rather silly but heartwarming premise. The minions and their (self-coined banana) language lends its own share of fun and comedy. The fourth instalment retains all those elements, but the script feels overstuffed and half-baked with multiple tracks not quite reaching their full potential. As a result, the film feels incomplete and conveniently rushed. It doesn't come together. Be it the Gru-Maxime rivalry bit or family relocation crisis, it doesn't come to fruition to achieve the desired impact. It all feels a bit scattered and a half-hearted attempt to keep the franchise going. Does it have its enjoyable moments? Yes. But these moments never come together to turn into one story that embodies that heartwarming quality. Then there's also the 'Avengers gone wrong' track where minions are turned into mega minions, but they do more damage than good. Not many scenes stay with you unlike the previous films barring one. Lucy being chased down by a disgruntled woman has Terminator's title music playing in the background, making it the funniest chase sequence of the movie. Despicable 4 is serviceably sweet and enjoyable but not the best in the series\""
      ],
      "metadata": {
        "id": "5X8gXzIZBTMY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "model = \"gpt-3.5-turbo\"\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "     \"content\": \"Identify the sentiment of the movie. Just say Positive/NEgative\"},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": review\n",
        "    }\n",
        "]\n",
        "\n",
        "data = {\n",
        "    \"model\": model,\n",
        "    \"messages\": messages\n",
        "}\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {api_key}\"\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\",\n",
        "                         headers=headers, data=json.dumps(data))\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sFJVDzQCDjH",
        "outputId": "4f39c30c-5149-4a95-c3da-53c6015b60ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'chatcmpl-9jk5ZamCQMqWv3FpHJ8QAMXy6zmNR', 'object': 'chat.completion', 'created': 1720688953, 'model': 'gpt-3.5-turbo-0125', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Negative'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 411, 'completion_tokens': 1, 'total_tokens': 412}, 'system_fingerprint': None, 'monthlyCost': 0.0012389999999999999, 'cost': 0.0012389999999999999, 'monthlyRequests': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: How to check if whisper-1 was created on 2023-03-04?\n",
        "\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "api_key = userdata.get('AIR_PROXY_TOKEN')\n",
        "\n",
        "# Get model details\n",
        "r = requests.get(\"https://aiproxy.sanand.workers.dev/openai/v1/models\", headers={\n",
        "    \"Authorization\": f\"Bearer {api_key}\"\n",
        "})\n",
        "models = r.json()['data']\n",
        "\n",
        "# Find whisper-1 and check its creation date\n",
        "for model in models:\n",
        "  if model['id'] == 'gpt-4-1106-preview':\n",
        "    created_at = model.get('created')\n",
        "    # This is UNIX timestamp, represent the number of seconds that have elapsed since January 1, 1970 at 00:00:00 UTC\n",
        "    date_time = datetime.datetime.fromtimestamp(created_at)\n",
        "    print(date_time)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "TyHWMIDZDGdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0dc63c-96e8-4173-be36-d3be2a13cd7a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-02 20:33:26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  Get a \\list of all OpenAI models that were created before 15 May 2024,Sort the models as most recent first.\n",
        "\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "api_key = userdata.get('AIR_PROXY_TOKEN')\n",
        "\n",
        "# Get model details\n",
        "r = requests.get(\"https://aiproxy.sanand.workers.dev/openai/v1/models\", headers={\n",
        "    \"Authorization\": f\"Bearer {api_key}\"\n",
        "})\n",
        "models = r.json()['data']\n",
        "\n",
        "# Filter models created before 15 May 2024 and sort\n",
        "cutoff_date = datetime.datetime(2024, 5, 15)\n",
        "old_models = [model for model in models if datetime.datetime.fromtimestamp(model.get('created')) < cutoff_date]\n",
        "old_models.sort(key=lambda x: x.get('created'), reverse=True)  # Sort by creation date, most recent first\n",
        "\n",
        "# Print the list of old models\n",
        "for model in old_models:\n",
        "    print(model['id'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm9HX464qjZa",
        "outputId": "27e041a1-29d6-4b3c-a6c6-9f178b96764b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4o-2024-05-13\n",
            "gpt-4o\n",
            "gpt-4-turbo-2024-04-09\n",
            "gpt-4-turbo\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4-turbo-preview\n",
            "gpt-4-0125-preview\n",
            "text-embedding-3-large\n",
            "text-embedding-3-small\n",
            "tts-1-hd-1106\n",
            "tts-1-1106\n",
            "tts-1-hd\n",
            "gpt-3.5-turbo-1106\n",
            "gpt-4-1106-preview\n",
            "dall-e-2\n",
            "dall-e-3\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-3.5-turbo-instruct\n",
            "babbage-002\n",
            "davinci-002\n",
            "gpt-4\n",
            "gpt-4-0613\n",
            "gpt-3.5-turbo-16k\n",
            "tts-1\n",
            "gpt-3.5-turbo\n",
            "whisper-1\n",
            "text-embedding-ada-002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: How to check if gpt-3.5-turbo-1106 was created 12 models before gpt-4-0613\n",
        "\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "api_key = userdata.get('AIR_PROXY_TOKEN')\n",
        "\n",
        "# Get model details\n",
        "r = requests.get(\"https://aiproxy.sanand.workers.dev/openai/v1/models\", headers={\n",
        "    \"Authorization\": f\"Bearer {api_key}\"\n",
        "})\n",
        "models = r.json()['data']\n",
        "\n",
        "# Extract model IDs and creation dates\n",
        "model_data = []\n",
        "for model in models:\n",
        "  model_data.append((model['id'], model.get('created')))\n",
        "\n",
        "# Sort models by creation date (oldest to newest)\n",
        "model_data.sort(key=lambda x: x[1])\n",
        "\n",
        "# Find indices of the two models\n",
        "index_35 = None\n",
        "index_4 = None\n",
        "for i, (model_id, _) in enumerate(model_data):\n",
        "  if model_id == 'gpt-3.5-turbo-1106':\n",
        "    index_35 = i\n",
        "  elif model_id == 'gpt-4-0613':\n",
        "    index_4 = i\n",
        "\n",
        "# Check if gpt-3.5-turbo-1106 was created 12 models before gpt-4-0613\n",
        "if index_35 is not None and index_4 is not None and index_4 - index_35 == 12:\n",
        "  print(\"Yes, gpt-3.5-turbo-1106 was created 12 models before gpt-4-0613.\")\n",
        "else:\n",
        "  print(\"No, gpt-3.5-turbo-1106 was not created 12 models before gpt-4-0613.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkTzbWqXpG8W",
        "outputId": "88b53908-814d-4ee9-87c2-d11b7a3295d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, gpt-3.5-turbo-1106 was not created 12 models before gpt-4-0613.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "\n",
        "api_key = userdata.get(\"AIR_PROXY_TOKEN\")\n",
        "PROXY_URL = 'https://aiproxy.sanand.workers.dev/openai/'\n",
        "\n",
        "word = \"Industry\"\n",
        "value = 0.019484397539201215\n",
        "\n",
        "url = f\"{PROXY_URL}v1/embeddings\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "data = {\n",
        "    \"input\": word,\n",
        "    \"model\": \"text-embedding-3-small\",\n",
        "    \"encoding_format\": \"float\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "embeddings = response.json()['data'][0]['embedding']\n",
        "\n",
        "count = sum(1 for x in embeddings if x > value)\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFxKDGGUvDo6",
        "outputId": "f09a6821-c9f0-4b98-bc16-44503acd7f41"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "embeddings = {}\n",
        "words = [\"Research\", \"Different\"]\n",
        "\n",
        "api_key = userdata.get(\"AIR_PROXY_TOKEN\")\n",
        "PROXY_URL = 'https://aiproxy.sanand.workers.dev/openai/'\n",
        "url = f\"{PROXY_URL}v1/embeddings\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "data = {\n",
        "    \"input\": words,\n",
        "    \"model\": \"text-embedding-3-small\",\n",
        "    \"encoding_format\": \"float\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "\n",
        "for word, embedding in zip(words, response.json()['data']):\n",
        "    embeddings[word] = np.array(embedding['embedding'])\n",
        "\n",
        "np.dot(embeddings[words[0]], embeddings[words[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb2kAeqIv_UE",
        "outputId": "14f048e7-db3b-4aaf-d400-2c7bf0374e3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26000444908835685"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "embeddings = {}\n",
        "\n",
        "target = \"Adventure\"\n",
        "word_lists = {\n",
        "    \"A\": [\"Consider\", \"Astronomy\", \"Generation\", \"Marketing\"],\n",
        "    \"B\": [\"Abundance\", \"Majority\", \"Celebrate\", \"Fantastic\"],\n",
        "    \"C\": [\"Knowledge\", \"Authority\", \"Optimistic\", \"Solution\"],\n",
        "    \"D\": [\"Encourage\", \"Important\", \"Ambitious\", \"Knowledge\"]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "unique = list(set(word for words_list in word_lists.values() for word in words_list))\n",
        "unique.append(target)\n",
        "\n",
        "api_key = userdata.get(\"AIR_PROXY_TOKEN\")\n",
        "PROXY_URL = 'https://aiproxy.sanand.workers.dev/openai/'\n",
        "url = f\"{PROXY_URL}v1/embeddings\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "data = {\n",
        "    \"input\": unique,\n",
        "    \"model\": \"text-embedding-3-small\",\n",
        "    \"encoding_format\": \"float\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "\n",
        "for word, embedding in zip(unique, response.json()['data']):\n",
        "    embeddings[word] = np.array(embedding['embedding'])\n",
        "\n",
        "average_similarities = {}\n",
        "\n",
        "for key, word_list in word_lists.items():\n",
        "    similarities = [np.dot(embeddings[target], embeddings[word]) for word in word_list if word != target]\n",
        "    average_similarities[key] = np.mean(similarities)\n",
        "\n",
        "max(average_similarities, key=average_similarities.get)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "1-HT8nICwWJ5",
        "outputId": "46f931b0-5fc6-4d1b-ffed-1e88df437551"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "input_text = \"Der Himmel war klar und blau, als die Sonne langsam hinter den Bergen verschwand\"\n",
        "cost_per_million_tokens_cent = 50\n",
        "tokens = num_tokens_from_string(input_text, \"gpt-3.5-turbo-0125\")\n",
        "total_cost_cent = (tokens / 1_000_000) * cost_per_million_tokens_cent\n",
        "total_cost_cent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIUWxBIZwrbv",
        "outputId": "0c85088f-d913-4ed3-c434-a3efe3e90890"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m1.0/1.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a, b, *_ = [1, 2, 3, 4, 5]\n",
        "#print(_)\n",
        "\n",
        "*__,a,b, = [1, 2, 3, 4, 5]\n",
        "print(__,_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27OP7j4rxXmj",
        "outputId": "128bb16d-634c-4057-8603-1e2e890ff951"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3] [3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urMar9ulRvgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}